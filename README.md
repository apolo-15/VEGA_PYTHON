VEGA
 English
Overview

VEGA is a desktop AI assistant built in Python, developed as a personal and experimental project.

Its main purpose is to explore how a local Large Language Model (LLM) can be integrated into a desktop graphical interface, combining voice interaction, text-based communication, and external services, while preserving a clean and maintainable codebase.

The project focuses on architectural clarity, modularity, and progressive refactoring rather than on delivering a finished or commercial product.

What VEGA Does

VEGA runs a local language model using Ollama and LangChain and exposes it through a desktop application built with PySide6 (Qt).

Interaction can happen either by text or voice. Voice input and audio output are handled asynchronously to keep the interface responsive. Around the core LLM, several independent services are integrated, such as weather queries, media playback, web searches, and messaging.

Contacts and other persistent data are stored locally and can be managed visually from the GUI, without modifying the code.

Project Structure

The codebase is organized to keep responsibilities clearly separated.

The views package contains all user interface components built with PySide6.
The controllers package handles application flow and coordinates interactions between UI, services, and the language model.
The models package contains the LLM integration and memory-related logic.
The services package groups independent features such as weather, playback, messaging, and contact management.

This structure allows the project to grow without accumulating unnecessary coupling or technical debt.

Philosophy

VEGA is intentionally designed as a learning-driven project.

It favors readability, refactoring, and explicit design decisions over speed or feature count. The goal is not to build a finished assistant, but to maintain a solid foundation that can evolve over time as new ideas and improvements are explored.

 Espa帽ol
Descripci贸n general

VEGA es un asistente de escritorio desarrollado en Python, concebido como un proyecto personal de aprendizaje y experimentaci贸n.

Su objetivo principal es explorar c贸mo integrar un modelo de lenguaje local (LLM) en una interfaz gr谩fica de escritorio, combinando interacci贸n por voz, comunicaci贸n por texto y distintos servicios externos, manteniendo una base de c贸digo clara y mantenible.

El proyecto prioriza la arquitectura, la modularidad y la refactorizaci贸n progresiva frente a la idea de producto terminado.

Qu茅 hace VEGA

VEGA ejecuta un modelo de lenguaje local mediante Ollama y LangChain, integrado en una aplicaci贸n de escritorio construida con PySide6 (Qt).

La interacci贸n puede realizarse tanto por texto como por voz. La entrada de audio y la salida por voz se gestionan de forma as铆ncrona para no bloquear la interfaz. Alrededor del LLM se integran distintos servicios independientes, como consultas meteorol贸gicas, reproducci贸n multimedia, b煤squedas web y mensajer铆a.

Los contactos y otros datos persistentes se almacenan localmente y pueden gestionarse de forma visual desde la propia interfaz, sin necesidad de modificar el c贸digo.

Estructura del proyecto

El c贸digo est谩 organizado para mantener una separaci贸n clara de responsabilidades.

El paquete views contiene todos los componentes de la interfaz gr谩fica desarrollados con PySide6.
El paquete controllers gestiona el flujo de la aplicaci贸n y coordina la interacci贸n entre la interfaz, los servicios y el modelo de lenguaje.
El paquete models incluye la integraci贸n del LLM y la l贸gica relacionada con la memoria.
El paquete services agrupa las funcionalidades independientes como el tiempo, la reproducci贸n, la mensajer铆a y la gesti贸n de contactos.

Esta organizaci贸n facilita la evoluci贸n del proyecto sin generar acoplamientos innecesarios.

Filosof铆a

VEGA est谩 planteado deliberadamente como un proyecto orientado al aprendizaje.

Se da prioridad a la legibilidad del c贸digo, a la refactorizaci贸n y a decisiones de dise帽o expl铆citas, por encima de la rapidez o del n煤mero de funcionalidades. No se trata de construir un asistente cerrado, sino de mantener una base s贸lida sobre la que seguir experimentando y mejorando con el tiempo.